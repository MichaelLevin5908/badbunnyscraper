{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of BlueSky Posts on #BadBunny and #SuperBowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv('sortedByLikes.csv')\n",
    "\n",
    "# create vader analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# this gets the scores\n",
    "def get_compound_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# add sentiment column\n",
    "df['compound_sentiment'] = df['text'].apply(get_compound_sentiment)\n",
    "\n",
    "# display first couple rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean sentiment\n",
    "average_sentiment = df['compound_sentiment'].mean()\n",
    "print(f'Average sentiment score: {average_sentiment:.3f}')\n",
    "\n",
    "# 5 most positive posts\n",
    "top_positive = df.nlargest(5, 'compound_sentiment')[['author', 'text', 'compound_sentiment']]\n",
    "print('\\nTop 5 Most Positive Posts:')\n",
    "print(top_positive)\n",
    "\n",
    "# 5 most negative posts\n",
    "top_negative = df.nsmallest(5, 'compound_sentiment')[['author', 'text', 'compound_sentiment']]\n",
    "print('\\nTop 5 Most Negative Posts:')\n",
    "print(top_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which posts are negative positive and neutral\n",
    "def categorize_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'Positive'\n",
    "    elif score < -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['sentiment_category'] = df['compound_sentiment'].apply(categorize_sentiment)\n",
    "sentiment_counts = df['sentiment_category'].value_counts()\n",
    "\n",
    "# plot the analysis\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=['green', 'gray', 'red'])\n",
    "plt.title('Proportion of Sentiment Scores in BlueSky Posts')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Discussion\n",
    "\n",
    "### Does the average sentiment score accurately represent the feelings towards your search terms, or is it being weighted towards another thing or event? Why is the average where it is?\n",
    "\n",
    "The average sentiment score of approximately 0.05 (slightly positive) may not fully represent feelings specifically towards #BadBunny and #SuperBowl, as the posts often discuss broader topics like politics, racism, and cultural representation. Many posts express outrage over MAGA backlash or ICE presence, which introduces negative sentiments, while others celebrate Bad Bunny's performance, adding positivity. The average is mildly positive because neutral or factual posts (e.g., news updates) balance out the polarized opinions, but it doesn't capture the intensity of debates around immigration and nationalism overshadowing the event itself.\n",
    "\n",
    "### Is there any correlation with the most positive or negative posts and likes, replies, etc.? How are these posts different from the other posts in your dataset? Do you agree with the sentiment analyzer that these posts are indeed very positive or negative?\n",
    "\n",
    "The top positive posts often have higher engagement (e.g., likes and reposts), as they celebrate Bad Bunny or criticize opponents humorously, resonating with fans. Negative posts, conversely, focus on conspiracy theories or racism, sometimes garnering replies for debate. These posts differ by being more opinionated and emotionally charged compared to neutral news shares. VADER accurately identifies them as extreme due to polarized language (e.g., \"disgusting\" for negative, \"exciting\" for positive), though context like sarcasm might be misread; overall, the analyzer aligns well with human interpretation.\n",
    "\n",
    "### How can you use this sentiment analysis to help you answer your research questions?\n",
    "\n",
    "Sentiment analysis reveals public discourse polarization on Bad Bunny's Super Bowl appearance, highlighting themes of cultural identity and political division. By correlating sentiment with engagement metrics, we can identify viral narratives, such as anti-MAGA sentiments driving interactions. This informs strategies for content moderation or marketing, showing how social media amplifies controversies. However, limitations like VADER's inability to detect irony mean combining with manual review for nuanced insights, ultimately quantifying emotional responses to guide research on media influence and audience reactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
